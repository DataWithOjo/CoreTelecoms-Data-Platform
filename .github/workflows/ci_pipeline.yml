name: CoreTelecoms CI Pipeline

on:
  pull_request:
    branches: [ "main" ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  push:
    branches: [ "**" ]
    paths-ignore:
      - '**.md'
      - 'docs/**'

jobs:
  quality-checks:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Linting Tools
        run: pip install flake8 sqlfluff

      - name: Lint Python Code (DAGs & Scripts)
        run: |
          # Check DAGs and Scripts folders at the root
          flake8 dags scripts --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Lint SQL Code (dbt Models)
        run: |
          # Lint dbt models inside dbt_project/models
          sqlfluff lint dbt_project/models --dialect snowflake

  unit-tests:
    name: Unit Testing
    runs-on: ubuntu-latest
    needs: quality-checks
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          pip install apache-airflow pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Airflow DAG Unit Tests
        env:
          AIRFLOW_HOME: ${{ github.workspace }}
        run: |
          # Add project root to PYTHONPATH so tests can import from 'dags' or 'scripts'
          export PYTHONPATH="${PYTHONPATH}:${{ github.workspace }}"
          
          # Run tests located in the root 'tests/' folder
          pytest tests/test_load_snowflake_pipeline.py