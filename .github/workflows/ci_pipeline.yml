name: CoreTelecoms CI Pipeline

on:
  pull_request:
    branches: [ "main" ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  push:
    branches: ["**"]
    paths-ignore:
      - '**.md'
      - 'docs/**'

jobs:
  quality-checks:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip' 

      - name: Install DBT, SQLFluff, and Python Dependencies
        run: |
          # Install core tools, DUCKDB adapter (for mocking), and flake8
          pip install --upgrade pip
          pip install dbt-core dbt-snowflake sqlfluff sqlfluff-templater-dbt flake8 dbt-duckdb 
          
          # Install dbt packages from packages.yml
          dbt deps --project-dir dbt_core_telecoms 

      - name: Create MOCK DBT profile for Linting
        run: |
          # CRITICAL FIX: Use DUCKDB to prevent the Snowflake adapter from forcing a network connection check.
          # The .sqlfluff file points to this location.
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          core_telecoms:
            target: ci_mock
            outputs:
              ci_mock:
                type: duckdb
                path: ":memory:"
                schema: "mock_schema"
          EOF

      - name: Lint Python Code (DAGs & Scripts)
        run: |
          flake8 dags scripts --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Lint SQL (dbt models via SQLFluff)
        run: |
          # Lint command relies entirely on the .sqlfluff file for profiles_dir, apply_dbt_builtins, etc.
          sqlfluff lint dbt_core_telecoms/models \
            --dialect snowflake \
            --templater dbt \
            --config .sqlfluff

  dbt-integration-tests:
    name: Integration & Data Tests
    runs-on: ubuntu-latest
    needs: quality-checks
    timeout-minutes: 20

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          
      - name: Install DBT Dependencies
        run: |
          # Install dbt-snowflake adapter and packages for this real connection job.
          pip install dbt-core dbt-snowflake
          dbt deps --project-dir dbt_core_telecoms
          
      - name: Create DBT profile (profiles.yml)
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
        run: |
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          core_telecoms:
            target: ci
            outputs:
              ci:
                type: snowflake
                account: "${SNOWFLAKE_ACCOUNT}"
                user: "${SNOWFLAKE_USER}"
                password: "${SNOWFLAKE_PASSWORD}"
                role: "${SNOWFLAKE_ROLE}"
                warehouse: "${SNOWFLAKE_WAREHOUSE}"
                database: "${SNOWFLAKE_DATABASE}"
                schema: "${SNOWFLAKE_SCHEMA}"
                threads: 4
                client_session_keep_alive: False
          EOF
      
      - name: Download previous manifest for state comparison
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: dbt-manifest
          path: dbt_state

      - name: Determine selector mode
        id: selector
        run: |
          if [ -f "dbt_state/manifest.json" ]; then
            echo "mode=state" >> $GITHUB_OUTPUT
          else
            echo "mode=full" >> $GITHUB_OUTPUT
          fi

      - name: Validate DBT Environment (Connection Check)
        run: dbt debug --project-dir dbt_core_telecoms --target ci

      - name: Compile Models
        run: dbt compile --project-dir dbt_core_telecoms --target ci

      - name: Run Modified Models
        if: steps.selector.outputs.mode == 'state'
        run: |
          dbt run --project-dir dbt_core_telecoms --target ci --select "state:modified+" --state dbt_state

      - name: Test Modified Models
        if: steps.selector.outputs.mode == 'state'
        run: |
          dbt test \
              --project-dir dbt_core_telecoms \
              --target ci \
              --select "state:modified+" \
              --state dbt_state

      - name: Run All Models (No prior manifest)
        if: steps.selector.outputs.mode == 'full'
        run: |
          dbt run --project-dir dbt_core_telecoms --target ci

      - name: Test All Models (No prior manifest)
        if: steps.selector.outputs.mode == 'full'
        run: |
          dbt test \
              --project-dir dbt_core_telecoms \
              --target ci

      - name: Upload manifest for next run
        uses: actions/upload-artifact@v4
        with:
          name: dbt-manifest
          path: dbt_core_telecoms/target/manifest.json

  unit-tests:
    name: Unit Testing
    runs-on: ubuntu-latest
    needs: quality-checks 

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            libssl-dev \
            libffi-dev \
            libpq-dev \
            libkrb5-dev \
            libsasl2-dev

      - name: Install Airflow 3.1.3 + Requirements.txt
        run: |
          pip install --upgrade pip

          # Install Airflow EXACTLY as your Docker image
          AIRFLOW_VERSION=3.1.3
          PYTHON_VERSION="3.12"
          CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"

          pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"

          # Install your project dependencies (same as your Docker image)
          pip install -r requirements.txt

          # Install pytest
          pip install pytest

      - name: Run Unit Tests
        env:
          AIRFLOW_HOME: ${{ github.workspace }}
        run: |
          export PYTHONPATH="${PYTHONPATH}:${{ github.workspace }}"
          pytest tests/