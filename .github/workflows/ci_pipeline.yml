name: CoreTelecoms CI Pipeline

on:
  pull_request:
    branches: [ "main" ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  push:
    branches: [ "**" ]
    paths-ignore:
      - '**.md'
      - 'docs/**'

jobs:
  quality-checks:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Linting Tools
        run: pip install flake8 sqlfluff sqlfluff-templater-dbt dbt-snowflake

      - name: Lint Python Code (DAGs & Scripts)
        run: |
          flake8 dags scripts --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Lint SQL Code (dbt Models)
        run: |
          DBT_DIR=$(dirname $(find . -name dbt_project.yml -type f | head -n 1))
          echo "Detected dbt project at: $DBT_DIR"

          export DBT_PROFILES_DIR=$DBT_DIR

          cat <<EOF > $DBT_DIR/profiles.yml
          core_telecoms:
            target: disabled
            outputs:
              disabled:
                type: snowflake
                account: dummy
                user: dummy
                password: dummy
                role: dummy
                warehouse: dummy
                database: dummy
                schema: dummy
                threads: 1
                client_session_keep_alive: false
          EOF

          dbt deps --project-dir "$DBT_DIR" --profiles-dir "$DBT_DIR"

          sqlfluff lint "$DBT_DIR/models" --dialect snowflake

  unit-tests:
    name: Unit Testing
    runs-on: ubuntu-latest
    needs: quality-checks
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install Dependencies
        run: |
          pip install apache-airflow pytest
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Airflow DAG Unit Tests
        env:
          AIRFLOW_HOME: ${{ github.workspace }}
        run: |
          export PYTHONPATH="${PYTHONPATH}:${{ github.workspace }}"
          pytest tests/test_load_snowflake_pipeline.py
